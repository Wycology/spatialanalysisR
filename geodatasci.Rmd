---
title: "Geo_Data_Sci_R"
author: "Wyclife Agumba Oluoch"
date: "1/22/2021"
output: html_document
---

### Loading Libraries to use 

Loading the necessary packages to use in the codes which will be helpful in analyzing geographic data in R.

```{r packages, include=FALSE}
library(sf)
library(tidyverse)
library(spdep)
library(extrafont)
#font_import()
#loadfonts(device = "win")
```

The data which I will use in the current work can be [directly downloaded](https://opendata.arcgis.com/datasets/f99ce43936d74f718e92a37a560ad875_0.zip), extracted from zipped folder, and saved in the sub-folder called *shp* inside the .Rmd file folder.

The next step is to read in the data using `st_read()`. I will call the created object honeybee

```{r loading, echo=FALSE, message=FALSE, warning=FALSE}
honeybee <- st_read('shp/HoneyBeePermits2017.shp')
```
There is a lot of information which we get by loading the data including path to the dataset being loaded, driver which has been used to load the file, geometry type, dimension, bounding box, and CRS We can extract such information individually, for example:

```{r geometry}
str(honeybee$geometry) 
```

This is telling us that we are working with a point feature. Such a cool information to have. Now we may need to know the coordinate reference system of our data

```{r coordinaes}
st_crs(honeybee)
```

This is returning a super helppful information. We can also have the information within the text as `r st_crs(honeybee)`. I still have no idea how the output will look like. Let us see by knitting the markdown. Everything thrown to text.

Now the next step would be to check for self intersection in our data.

```{r validity}
sum(st_is_valid(honeybee) == TRUE)
```

We do not have any problem of self-intersection in our dataset. Okay this is reminding me of something I was working on and worried how to solve it in QGIS without much success. That is I accidentally criss-crossed same line feature while digitizing rivers and I could not trace the object to edit it. I will create dummy feature with such error in QGIS and load it.

```{r dummy}
dummy <- st_read('shp/dummy.shp')
```

The dummy feature is read seamlessly. I know the line has crossed itself at some point. Let me now check for its validity.

```{r dummy_validity}
sum(st_is_valid(dummy) == TRUE)
```

This seams to be fine even though I kno the lines cut themselves at some point. Let me try this with a poygon. I will create two polygons, one kind of a rectangle and the other a funny shape which cuts itself. I think that the latter should be an invalid polygon. Here we go.

```{r dummy_poly}
dummy_poly <- st_read('shp/dummy_poly.shp')

```

Now let me check for the validity of the features I have in my dataset of the dummy_poly

```{r dummy_poly_validity}
sum(st_is_valid(dummy_poly) == TRUE)
```

Good, the point is now sinking home. Only one polygon is valid. The other two are intersecting with themselves hence invalid as polygon.

Now back to honeybee work. I want to project it to UTM zone 15N for Minnesota. I remember that earlier, while working with geocomputation with R, I developed a function which can help wth knowing the epsg code for any place on earth provided you know long and lat of the place, which I can get from Google Earth search for Minnesota.

```{r epsg}
lonlat2UTM <- function(lonlat){
  utm <- (floor((lonlat[1] + 180)/6) %% 60) + 1
  if(lonlat[2] > 0){
    utm + 32600
  } else{
    utm + 32700
  }
}
```

Cool, the function is created, now I can call it to get the epsg code best suited for Minnesota (lat = 46.729741°, long = -94.685798°)

```{r epsg_minnesota}
lonlat2UTM(c(-94.685798, 46.729741))
```

This is returning `r lonlat2UTM(c(-94.685798, 46.729741))` which is different from 26915 which has been used in the tutorial. Okay, they are using different datums or data :). 26915 is NAD.

Now I can project the honeybee data

```{r projecting}
honeybee_utm <- st_transform(honeybee, 26915)
```

We can check the crs of honeybee_utm.

```{r crs_check, message=FALSE, echo=FALSE, warning=FALSE}
st_crs(honeybee_utm)
```

Quite clear that the projection has been done successfully.

Now to create a plot of these points, we need at least to have a background map. Otherwise just points on a white background will not make much sense. So I will import some free background map.

```{r backmap}
neighborhoods <- st_read("https://opendata.arcgis.com/datasets/055ca54e5fcc47329f081c9ef51d038e_0.geojson") %>%
  st_transform(26915)
```

Cool, the original link failed and I had t navigate to the source to pick the new link which has then worked fine. Good.

I will load the necessary etrafont package as I prepare to use ggplot for the plotting of the map.

Now I can simply go ahead and generate the plot.

```{r ggplot}
ggplot() +
  geom_sf(data = neighborhoods, fill = '#e8eff7', color = '#8f98aa') +
  geom_sf(data = honeybee_utm, color = '#efcf2f') +
  theme_minimal() +
  theme(panel.grid.major = element_line('transparent'),
        axis.text = element_blank(),
        text = element_text(family = "Century Gothic")) +
  ggtitle('Honeybee Permits in Minneapolis')
```

That is a pretty fine map.

We can use the HiveType variable to color the points so that we can visually appreciate the distribution of hives by type within the area.

```{r names_of_variables}
colnames(honeybee_utm)
```

To use the variable of HiveType to color the points we make slight modification to our earlier plot.

```{r HiveType}
ggplot() +
  geom_sf(data = neighborhoods, fill = '#e8eff7', color = '#8f98aa') +
  geom_sf(data = honeybee_utm, aes(color = HiveType)) +
  theme_minimal() +
  theme(
    panel.grid.major = element_line('transparent'),
    axis.text = element_blank(),
    text = element_text(family = "Century Gothic")
  ) +
  ggtitle('Honeybee Permits in Minneapolis')
```

Great.Nice to see how the different types of hives are distributed across the Minneapolis.

In case I am not happy with the colors, I can assign them manually as:

```{r HiveType_color}
ggplot() +
  geom_sf(data = neighborhoods, fill = '#e8eff7', color = '#8f98aa') +
  geom_sf(data = honeybee_utm, aes(color = HiveType)) +
  scale_color_manual(values = c('purple', '#50a2e0')) +
  theme_minimal() +
  theme(
    panel.grid.major = element_line('transparent'),
    axis.text = element_blank(),
    text = element_text(family = "Century Gothic")
  ) +
  ggtitle('Honeybee Permits in Minneapolis')
```

Now I am interested in knowing the number of honeybee permits per neighborhood That is, how many points fall within each of the polygons.

### Spatial joins

This is calling for joining the two datasets into one. The type of join to use here is left join which is the default.

```{r join, message=FALSE, warning=FALSE, echo=FALSE}
nb_join <- st_join(neighborhoods, honeybee_utm)
head(nb_join)
```

Now we can go ahead and use dplyr verbs to count per unit/

```{r}
nb <- nb_join %>% 
  group_by(BDNAME) %>% 
  summarise(n_permits = n())
```

We can have a quick look at the distribution

```{r}
ggplot(nb, aes(x = n_permits)) +
  geom_histogram(binwidth = 1, color = 'white') +
  theme_minimal() +
  ggtitle('Permits per neighborhood') +
  theme(text = element_text(family = 'Century Gothic')) +
  labs(x = 'Number of Permits')
```

Majority of the neghborhoods (over 60) had only one permit. The maximum number of permits per neighborhood was 4 which was in less than 10 neighborhoods.

It is possible to color the map by number of permits.

```{r}
ggplot(nb) +
  geom_sf(aes(fill = n_permits), color = '#8f98aa') +
  scale_fill_gradient(low = '#f5f7d9',
                      high = '#aedd27',
                      guide = guide_legend(title = 'Permits')) +
  theme_minimal() +
  theme(panel.grid.major = element_line('transparent'),
        axis.text = element_blank(),
        text = element_text(family = 'Century Gothic')) +
  ggtitle('Honeybee Permits per \nNeighborhood in Minneapolis')
  
```

Checking the possible existance of spatial autocorrelation in the data. That is, are the points existance related?

```{r autocorrelation}
neighborhoods_sp <- as(nb, 'Spatial') # Converting the sf to sp
nb_obj <- poly2nb(neighborhoods_sp)   # Create neighborhood object
summary(nb_obj)
```

```{r}
weights <- nb2listw(nb_obj, style = 'B') # Creates a matrix of binary spatial weights (connected or not connected)
```

```{r}
moran(neighborhoods_sp$n_permits, weights, n = length(weights$neighbours), S0 = Szero(weights))
```

The Moran's I statistic is 0.085, very slight positive autocorrelation. Is this significant or not? We will use Monte Carlo Simulation for this test. This will randomly assign values to the polygons and calculates Moran's I for each iteration. It then compares the observed statistic to the generated distribution.

```{r}
set.seed(123)
moran.mc(neighborhoods_sp$n_permits, weights, nsim = 9999) # 10000 simulations
```

Being that our observed statistic is 0.085 with a p-value of 0.0675, we would say that our distribution is not different from a randomly distributed. Therefore, we now know that the honeybee permits are randomly distributed in Minneapolis at the neighborhood level. It's important to note this spatial unit, clustering calculations can be very different at different units.
